{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "905e8e89",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b5e99f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.notebook.plotting import render\n",
    "from ax.utils.tutorials.cnn_utils import train, evaluate\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aedf96",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31fa127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_path = 'skin-lesions/train/'\n",
    "data_valid_path = 'skin-lesions/valid/'\n",
    "data_test_path = 'skin-lesions/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7902e3a6",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/is-there-a-limit-on-how-disbalanced-a-train-set-can-be/26334/6?u=ptrblck\n",
    "\n",
    "Below is an example of the undersampler that we did not end up using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66354f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# train_dataset = torch.load('model_data/train_dataset.pt')\n",
    "train_dataset = torch.load('upd_train_data.pt')\n",
    "\n",
    "## UNDERSAMPLER \n",
    "\n",
    "# labels = []\n",
    "# for idx, (sample, target) in enumerate(tqdm(train_dataset, total=len(train_dataset))):\n",
    "#     labels.append(int(target))\n",
    "# cls_weights = torch.from_numpy(\n",
    "#     compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "# )\n",
    "\n",
    "# weights = cls_weights[labels]\n",
    "# sampler = WeightedRandomSampler(weights, len(labels), replacement=True)\n",
    "\n",
    "# print(cls_weights)\n",
    "# print(np.unique(labels))\n",
    "\n",
    "# # train_dataset = ImageFolder(data_train_path, transform = train_transform)\n",
    "\n",
    "valid_dataset = ImageFolder(data_valid_path, transform = test_transform)\n",
    "test_dataset = ImageFolder(data_test_path, transform = test_transform)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, sampler = sampler, batch_size = 64)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = 32, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6865663f",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02224572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798ca83aeab64688891d56f83ca530b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modified_outputs, labels = [], []\n",
    "for idx, (sample, target) in enumerate(tqdm(train_dataset, total=len(train_dataset))):\n",
    "    modified_outputs.append(sample.cpu().detach().numpy())\n",
    "    labels.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288d71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(modified_outputs), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b52b30",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/53666759/use-smote-to-oversample-image-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d46213",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "train_rows=len(X_train)\n",
    "X_train = X_train.reshape(train_rows,-1)\n",
    "\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "X_train = X_train.reshape(-1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf9bbf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([1626, 1626]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0ef5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9232347",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40c96e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNetwork, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            \n",
    "            #input: (3, 224, 244), output: (6, 190, 190)\n",
    "            torch.nn.Conv2d(3, 6, 35),\n",
    "            torch.nn.ReLU(),\n",
    "            #input: (6, 190, 190), output: (6, 95, 95)\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            torch.nn.Dropout(0.4),\n",
    "\n",
    "            #input: (6, 95, 95), output: (16, 61, 61)\n",
    "            torch.nn.Conv2d(6, 16, 35),\n",
    "            torch.nn.ReLU(),\n",
    "            #input: (16, 61, 61), output: (16, 30, 30)\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            torch.nn.Dropout(0.4),\n",
    "\n",
    "            #input: (16, 30, 30), output: (32, 11, 11)\n",
    "            torch.nn.Conv2d(16, 32, 20),\n",
    "            torch.nn.ReLU(),\n",
    "            #input: (32, 11, 11), output: (32, 5, 5)\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            torch.nn.Dropout(0.2),\n",
    "\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(32 * 5 * 5, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 84),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(84, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9df009",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5162b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, criterion, min_loss, optimizer, vectorize=False):\n",
    "    training_losses, valid_losses, accs = [],[],[]\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            if vectorize:\n",
    "                images = images.reshape(-1, 224 * 224 * 3)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            ps = model(images)\n",
    "            loss = criterion(ps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            training_loss += loss.item()\n",
    "        print(f\"\\tEPOCH: {epoch + 1}.. TRAINING LOSS: {training_loss}\")\n",
    "\n",
    "        training_losses.append(training_loss)\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        acc = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                if vectorize:\n",
    "                    images = images.reshape(-1, 224 * 224 * 3)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                ps = model(images)\n",
    "                loss = criterion(ps, labels)\n",
    "                \n",
    "                valid_loss += loss.item()\n",
    "                \n",
    "                _, top_class = ps.topk(1, dim = 1)\n",
    "                eq = top_class == labels.view(-1, 1)\n",
    "                acc += eq.sum().item()\n",
    "                \n",
    "        valid_losses.append(valid_loss)\n",
    "        accs.append(acc)\n",
    "        acc = (acc/len(valid_dataset)) * 100\n",
    "        print(\"EPOCHS: {}/{}.. \\tTRAINING LOSS: {:.6f}.. \\tVALIDATION LOSS: {:.6f}.. \\tACCURACY: {:.2f}%..\".format(epoch + 1, epochs, training_loss, valid_loss, acc))\n",
    "        \n",
    "        if valid_loss <= min_loss:\n",
    "            print(\"Saving Model {:.4f} ---> {:.4f}\".format(min_loss, valid_loss))\n",
    "            save_obj = OrderedDict([\n",
    "                (\"min_loss\", valid_loss),\n",
    "                (\"model\", model.state_dict())\n",
    "            ])\n",
    "            torch.save(save_obj, \"/melanoma_model.pt\")\n",
    "            min_loss = valid_loss\n",
    "            \n",
    "    return training_losses, valid_losses, accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093fc912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    classes = test_dataset.classes\n",
    "    total_correct = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            ps = model(images)\n",
    "            \n",
    "            ps = nn.Softmax(dim = 1)(ps)\n",
    "            \n",
    "            top_p, top_class = ps.topk(2, dim = 1)\n",
    "            eq = top_class == labels.view(-1, 1)\n",
    "            total_correct += eq.sum().item()\n",
    "            \n",
    "            if count % 50 == 0:\n",
    "                plt.imshow(transforms.ToPILImage()(images[0]))\n",
    "                plt.title(f\"P: {classes[top_class.item()]}.. C: {top_p.item() * 100}%.. GT: {classes[labels.item()]}..\")\n",
    "                plt.show()\n",
    "            \n",
    "            \n",
    "                \n",
    "            count += 1\n",
    "                \n",
    "    print(\"Total Correct: {}/{}\".format(total_correct, len(test_dataset)))\n",
    "    print(\"Total Accuracy: {:.2f}%\".format((total_correct/len(test_dataset)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59c9bb24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalNetwork(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 6, kernel_size=(35, 35), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Conv2d(6, 16, kernel_size=(35, 35), stride=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Conv2d(16, 32, kernel_size=(20, 20), stride=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Dropout(p=0.2, inplace=False)\n",
       "    (12): Flatten(start_dim=1, end_dim=-1)\n",
       "    (13): Linear(in_features=800, out_features=512, bias=True)\n",
       "    (14): ReLU()\n",
       "    (15): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (16): ReLU()\n",
       "    (17): Linear(in_features=128, out_features=84, bias=True)\n",
       "    (18): ReLU()\n",
       "    (19): Linear(in_features=84, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvolutionalNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0227427e",
   "metadata": {},
   "source": [
    "## Bayesian Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a990ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_net(parameterization):\n",
    "\n",
    "    model = ConvolutionalNetwork().to(device)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False # Freeze feature extractor\n",
    "        \n",
    "    return model # return untrained model\n",
    "\n",
    "\n",
    "def net_train(net, train_loader, parameters, dtype, device):\n",
    "    net.to(dtype=dtype, device=device)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), # or any optimizer you prefer \n",
    "                        lr=parameters.get(\"lr\", 0.001), # 0.001 is used if no lr is specified\n",
    "                        weight_decay=parameters.get('weight_decay', 0.1)\n",
    "    )\n",
    "\n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "      optimizer,\n",
    "      step_size=int(parameters.get(\"step_size\", 30)),\n",
    "      gamma=parameters.get(\"gamma\", 1.0),  # default is no learning rate decay\n",
    "    )\n",
    "\n",
    "    num_epochs = parameters.get(\"num_epochs\", 2) # Play around with epoch number\n",
    "    # Train Network\n",
    "    for _ in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            # move data to proper dtype and device\n",
    "            inputs = inputs.to(dtype=dtype, device=device)\n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.requires_grad=True\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        return net\n",
    "\n",
    "\n",
    "def train_evaluate(parameterization):\n",
    "\n",
    "    # constructing a new training data loader allows us to tune the batch size\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                batch_size=parameterization.get(\"batchsize\", 32),\n",
    "                                shuffle=True)\n",
    "        \n",
    "    # Get neural net\n",
    "    untrained_net = init_net(parameterization)\n",
    "    \n",
    "    # train\n",
    "    trained_net = net_train(net=untrained_net, train_loader=train_loader, \n",
    "                            parameters=parameterization, dtype=torch.float, device=device)\n",
    "    \n",
    "    # return the accuracy of the model as it was trained in this run\n",
    "    return evaluate(\n",
    "        net=trained_net,\n",
    "        data_loader=test_loader,\n",
    "        dtype=torch.float,\n",
    "        device=device,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4cc41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_parameters, values, experiment, model = optimize(\n",
    "    parameters=[\n",
    "        {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [1e-6, 0.4], \"log_scale\": True},\n",
    "        {\"name\": \"batchsize\", \"type\": \"range\", \"bounds\": [16, 128]},\n",
    "        {\"name\": \"weight_decay\", \"type\": \"range\", \"bounds\": [0.0, 0.1]},\n",
    "#         {\"name\": \"max_epoch\", \"type\": \"range\", \"bounds\": [1, 30]},\n",
    "#         {\"name\": \"stepsize\", \"type\": \"range\", \"bounds\": [20, 40]},        \n",
    "    ],\n",
    "  \n",
    "    evaluation_function=train_evaluate,\n",
    "    objective_name='accuracy',\n",
    ")\n",
    "\n",
    "print(best_parameters)\n",
    "means, covariances = values\n",
    "print(means)\n",
    "print(covariances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6acccb",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Below is not the full training loop. Full training loop was run on Google Colab and the instance was lost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = 68, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ab7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEPOCH: 1.. TRAINING LOSS: 35.20852941274643\n",
      "EPOCHS: 1/50.. \tTRAINING LOSS: 35.208529.. \tVALIDATION LOSS: 3.287747.. \tACCURACY: 66.67%..\n",
      "\tEPOCH: 2.. TRAINING LOSS: 34.93632787466049\n",
      "EPOCHS: 2/50.. \tTRAINING LOSS: 34.936328.. \tVALIDATION LOSS: 3.409671.. \tACCURACY: 54.00%..\n",
      "\tEPOCH: 3.. TRAINING LOSS: 34.83892202377319\n",
      "EPOCHS: 3/50.. \tTRAINING LOSS: 34.838922.. \tVALIDATION LOSS: 3.390417.. \tACCURACY: 54.67%..\n",
      "\tEPOCH: 4.. TRAINING LOSS: 34.7320693731308\n",
      "EPOCHS: 4/50.. \tTRAINING LOSS: 34.732069.. \tVALIDATION LOSS: 3.459699.. \tACCURACY: 48.00%..\n",
      "\tEPOCH: 5.. TRAINING LOSS: 34.5806400179863\n",
      "EPOCHS: 5/50.. \tTRAINING LOSS: 34.580640.. \tVALIDATION LOSS: 3.363219.. \tACCURACY: 54.67%..\n",
      "\tEPOCH: 6.. TRAINING LOSS: 34.5492085814476\n",
      "EPOCHS: 6/50.. \tTRAINING LOSS: 34.549209.. \tVALIDATION LOSS: 3.515167.. \tACCURACY: 46.00%..\n",
      "\tEPOCH: 7.. TRAINING LOSS: 34.43019449710846\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = ConvolutionalNetwork().to(device)\n",
    "\n",
    "LEARNING_RATE = 3.470303960695998e-05\n",
    "EPOCHS = 50\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "min_loss = -1\n",
    "train_loss, valid_loss, accs = train(model, EPOCHS, criterion, min_loss, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
